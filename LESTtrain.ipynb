{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6171,"status":"ok","timestamp":1718526509235,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"95823465-9320-4607-87e7-736bc903473e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3101\n","Total X variables: 182256\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'20023kt 9999 prec0n CL0 CM0 15 08 q1021 22014G25KT 160V290 CAVOK 19/03 Q1021 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[778, 1, 2, 5, 3, 16, 12, 28, 1713, 710, 15, 43, 39, 28, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'09007kt 9999 prec0n CL0 CM0 02 -2 q1033 VRB02KT CAVOK M00/M02 Q1032 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[159, 1, 2, 5, 3, 48, 465, 128, 44, 15, 331, 380, 100, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[   0,    0,    0,    0,    0,  778,    1,    2,    5,    3,   16,\n","          12,   28],\n","       [   0,    0,    0,    0,  778,    1,    2,    5,    3,   16,   12,\n","          28, 1713],\n","       [   0,    0,    0,  778,    1,    2,    5,    3,   16,   12,   28,\n","        1713,  710],\n","       [   0,    0,  778,    1,    2,    5,    3,   16,   12,   28, 1713,\n","         710,   15],\n","       [   0,  778,    1,    2,    5,    3,   16,   12,   28, 1713,  710,\n","          15,   43],\n","       [ 778,    1,    2,    5,    3,   16,   12,   28, 1713,  710,   15,\n","          43,   39],\n","       [   1,    2,    5,    3,   16,   12,   28, 1713,  710,   15,   43,\n","          39,   28],\n","       [   0,    0,    0,    0,    0,  159,    1,    2,    5,    3,   48,\n","         465,  128],\n","       [   0,    0,    0,    0,  159,    1,    2,    5,    3,   48,  465,\n","         128,   44],\n","       [   0,    0,    0,  159,    1,    2,    5,    3,   48,  465,  128,\n","          44,   15],\n","       [   0,    0,  159,    1,    2,    5,    3,   48,  465,  128,   44,\n","          15,  331],\n","       [   0,  159,    1,    2,    5,    3,   48,  465,  128,   44,   15,\n","         331,  380],\n","       [ 159,    1,    2,    5,    3,   48,  465,  128,   44,   15,  331,\n","         380,  100],\n","       [   0,    0,    0,    0,    0,  388,    1,   19,   34,    3,    7,\n","           6,   62],\n","       [   0,    0,    0,    0,  388,    1,   19,   34,    3,    7,    6,\n","          62,  302],\n","       [   0,    0,    0,  388,    1,   19,   34,    3,    7,    6,   62,\n","         302,  171],\n","       [   0,    0,  388,    1,   19,   34,    3,    7,    6,   62,  302,\n","         171,   69],\n","       [   0,  388,    1,   19,   34,    3,    7,    6,   62,  302,  171,\n","          69,  151],\n","       [ 388,    1,   19,   34,    3,    7,    6,   62,  302,  171,   69,\n","         151,  116],\n","       [   1,   19,   34,    3,    7,    6,   62,  302,  171,   69,  151,\n","         116, 1032],\n","       [  19,   34,    3,    7,    6,   62,  302,  171,   69,  151,  116,\n","        1032,    7],\n","       [  34,    3,    7,    6,   62,  302,  171,   69,  151,  116, 1032,\n","           7,    6],\n","       [   3,    7,    6,   62,  302,  171,   69,  151,  116, 1032,    7,\n","           6,   72],\n","       [   7,    6,   62,  302,  171,   69,  151,  116, 1032,    7,    6,\n","          72,   11],\n","       [   6,   62,  302,  171,   69,  151,  116, 1032,    7,    6,   72,\n","          11,   21]], dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'prec0n': 2,\n"," 'cm0': 3,\n"," 'nosig': 4,\n"," 'cl0': 5,\n"," '11': 6,\n"," '12': 7,\n"," '10': 8,\n"," '09': 9,\n"," '13': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEST/LESTfusion.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEST/LESTtexts_test.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/gpt/LEST/LESTtokenizer.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1718527795943,"user_tz":-120,"elapsed":550045,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"2820768c-879b-4afb-8fde-c28932b04c8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","356/356 [==============================] - 28s 69ms/step - loss: 3.7650 - accuracy: 0.2191\n","Epoch 2/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.6732 - accuracy: 0.3152\n","Epoch 3/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.4100 - accuracy: 0.3526\n","Epoch 4/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.2960 - accuracy: 0.3707\n","Epoch 5/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.2213 - accuracy: 0.3830\n","Epoch 6/50\n","356/356 [==============================] - 24s 69ms/step - loss: 2.1588 - accuracy: 0.3924\n","Epoch 7/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.1027 - accuracy: 0.4029\n","Epoch 8/50\n","356/356 [==============================] - 24s 68ms/step - loss: 2.0426 - accuracy: 0.4156\n","Epoch 9/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.9853 - accuracy: 0.4254\n","Epoch 10/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.9311 - accuracy: 0.4376\n","Epoch 11/50\n","356/356 [==============================] - 25s 69ms/step - loss: 1.8762 - accuracy: 0.4499\n","Epoch 12/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.8266 - accuracy: 0.4618\n","Epoch 13/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.7761 - accuracy: 0.4729\n","Epoch 14/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.7363 - accuracy: 0.4806\n","Epoch 15/50\n","356/356 [==============================] - 25s 69ms/step - loss: 1.6916 - accuracy: 0.4931\n","Epoch 16/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.6554 - accuracy: 0.4996\n","Epoch 17/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.6187 - accuracy: 0.5094\n","Epoch 18/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.5875 - accuracy: 0.5162\n","Epoch 19/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.5615 - accuracy: 0.5225\n","Epoch 20/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.5345 - accuracy: 0.5301\n","Epoch 21/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.5076 - accuracy: 0.5367\n","Epoch 22/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.4827 - accuracy: 0.5422\n","Epoch 23/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.4689 - accuracy: 0.5463\n","Epoch 24/50\n","356/356 [==============================] - 25s 70ms/step - loss: 1.4439 - accuracy: 0.5533\n","Epoch 25/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.4309 - accuracy: 0.5547\n","Epoch 26/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.4137 - accuracy: 0.5601\n","Epoch 27/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3997 - accuracy: 0.5620\n","Epoch 28/50\n","356/356 [==============================] - 25s 69ms/step - loss: 1.3859 - accuracy: 0.5658\n","Epoch 29/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.3732 - accuracy: 0.5691\n","Epoch 30/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3651 - accuracy: 0.5701\n","Epoch 31/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3566 - accuracy: 0.5732\n","Epoch 32/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.3465 - accuracy: 0.5757\n","Epoch 33/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.3385 - accuracy: 0.5767\n","Epoch 34/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3224 - accuracy: 0.5817\n","Epoch 35/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3209 - accuracy: 0.5824\n","Epoch 36/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3205 - accuracy: 0.5826\n","Epoch 37/50\n","356/356 [==============================] - 25s 69ms/step - loss: 1.3188 - accuracy: 0.5824\n","Epoch 38/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.3190 - accuracy: 0.5813\n","Epoch 39/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3034 - accuracy: 0.5863\n","Epoch 40/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.2961 - accuracy: 0.5883\n","Epoch 41/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.2877 - accuracy: 0.5889\n","Epoch 42/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.2897 - accuracy: 0.5902\n","Epoch 43/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.3142 - accuracy: 0.5816\n","Epoch 44/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.2873 - accuracy: 0.5894\n","Epoch 45/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.2878 - accuracy: 0.5887\n","Epoch 46/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.2786 - accuracy: 0.5907\n","Epoch 47/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.2748 - accuracy: 0.5922\n","Epoch 48/50\n","356/356 [==============================] - 24s 68ms/step - loss: 1.2853 - accuracy: 0.5888\n","Epoch 49/50\n","356/356 [==============================] - 25s 69ms/step - loss: 1.2749 - accuracy: 0.5919\n","Epoch 50/50\n","356/356 [==============================] - 24s 69ms/step - loss: 1.2731 - accuracy: 0.5919\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=50,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEST/LESTmodel.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"1O8G4reMxCHpAClgeClO3AUNMzzwMplKS","authorship_tag":"ABX9TyPjhVkgQ+RWIIWrmGazo5Hp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}