{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9249,"status":"ok","timestamp":1718527980006,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"094bcfd6-bfd7-463b-c0e7-66476efa3321"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3007\n","Total X variables: 175820\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'35013kt 9999 prec0n CL0 CM0 10 07 q1008 27005KT 240V300 8000 SCT006 BKN009 OVC012 11/11 Q1008 TEMPO 3000 BR BKN010'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[455,\n"," 1,\n"," 2,\n"," 5,\n"," 3,\n"," 10,\n"," 17,\n"," 93,\n"," 215,\n"," 162,\n"," 75,\n"," 343,\n"," 208,\n"," 795,\n"," 8,\n"," 8,\n"," 93,\n"," 16,\n"," 31,\n"," 52,\n"," 60]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'17001kt 9999 prec0n CL0 CM0 11 11 q1018 VRB01KT 9999 FEW001 14/13 Q1017 NOSIG'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[377, 1, 2, 5, 3, 8, 8, 20, 55, 1, 238, 11, 9, 21, 4]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[  0,   0,   0,   0,   0, 455,   1,   2,   5,   3,  10,  17,  93],\n","       [  0,   0,   0,   0, 455,   1,   2,   5,   3,  10,  17,  93, 215],\n","       [  0,   0,   0, 455,   1,   2,   5,   3,  10,  17,  93, 215, 162],\n","       [  0,   0, 455,   1,   2,   5,   3,  10,  17,  93, 215, 162,  75],\n","       [  0, 455,   1,   2,   5,   3,  10,  17,  93, 215, 162,  75, 343],\n","       [455,   1,   2,   5,   3,  10,  17,  93, 215, 162,  75, 343, 208],\n","       [  1,   2,   5,   3,  10,  17,  93, 215, 162,  75, 343, 208, 795],\n","       [  2,   5,   3,  10,  17,  93, 215, 162,  75, 343, 208, 795,   8],\n","       [  5,   3,  10,  17,  93, 215, 162,  75, 343, 208, 795,   8,   8],\n","       [  3,  10,  17,  93, 215, 162,  75, 343, 208, 795,   8,   8,  93],\n","       [ 10,  17,  93, 215, 162,  75, 343, 208, 795,   8,   8,  93,  16],\n","       [ 17,  93, 215, 162,  75, 343, 208, 795,   8,   8,  93,  16,  31],\n","       [ 93, 215, 162,  75, 343, 208, 795,   8,   8,  93,  16,  31,  52],\n","       [  0,   0,   0,   0,   0, 377,   1,   2,   5,   3,   8,   8,  20],\n","       [  0,   0,   0,   0, 377,   1,   2,   5,   3,   8,   8,  20,  55],\n","       [  0,   0,   0, 377,   1,   2,   5,   3,   8,   8,  20,  55,   1],\n","       [  0,   0, 377,   1,   2,   5,   3,   8,   8,  20,  55,   1, 238],\n","       [  0, 377,   1,   2,   5,   3,   8,   8,  20,  55,   1, 238,  11],\n","       [377,   1,   2,   5,   3,   8,   8,  20,  55,   1, 238,  11,   9],\n","       [  1,   2,   5,   3,   8,   8,  20,  55,   1, 238,  11,   9,  21],\n","       [  0,   0,   0,   0,   0,  80,   1,   2,   5,   3,  18,  12,  23],\n","       [  0,   0,   0,   0,  80,   1,   2,   5,   3,  18,  12,  23,  38],\n","       [  0,   0,   0,  80,   1,   2,   5,   3,  18,  12,  23,  38,   6],\n","       [  0,   0,  80,   1,   2,   5,   3,  18,  12,  23,  38,   6,  49],\n","       [  0,  80,   1,   2,   5,   3,  18,  12,  23,  38,   6,  49,  10]],\n","      dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'prec0n': 2,\n"," 'cm0': 3,\n"," 'nosig': 4,\n"," 'cl0': 5,\n"," 'cavok': 6,\n"," '12': 7,\n"," '11': 8,\n"," '13': 9,\n"," '10': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXfusion.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXtexts_test.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXtokenizer_config.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1718529213703,"user_tz":-120,"elapsed":151058,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"c6b12879-b926-4c5b-dee3-18591b24d138"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","344/344 [==============================] - 27s 68ms/step - loss: 3.9756 - accuracy: 0.2120\n","Epoch 2/50\n","344/344 [==============================] - 23s 68ms/step - loss: 2.7674 - accuracy: 0.3198\n","Epoch 3/50\n","344/344 [==============================] - 24s 69ms/step - loss: 2.4562 - accuracy: 0.3625\n","Epoch 4/50\n","344/344 [==============================] - 24s 68ms/step - loss: 2.3422 - accuracy: 0.3765\n","Epoch 5/50\n","344/344 [==============================] - 23s 68ms/step - loss: 2.2724 - accuracy: 0.3873\n","Epoch 6/50\n","344/344 [==============================] - 23s 68ms/step - loss: 2.2127 - accuracy: 0.3943\n","Epoch 7/50\n","344/344 [==============================] - 24s 68ms/step - loss: 2.1613 - accuracy: 0.4042\n","Epoch 8/50\n","344/344 [==============================] - 24s 69ms/step - loss: 2.1185 - accuracy: 0.4092\n","Epoch 9/50\n","344/344 [==============================] - 24s 69ms/step - loss: 2.0715 - accuracy: 0.4167\n","Epoch 10/50\n","344/344 [==============================] - 23s 68ms/step - loss: 2.0265 - accuracy: 0.4260\n","Epoch 11/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.9865 - accuracy: 0.4324\n","Epoch 12/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.9421 - accuracy: 0.4422\n","Epoch 13/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.9026 - accuracy: 0.4500\n","Epoch 14/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.8625 - accuracy: 0.4574\n","Epoch 15/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.8194 - accuracy: 0.4671\n","Epoch 16/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.7782 - accuracy: 0.4767\n","Epoch 17/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.7418 - accuracy: 0.4849\n","Epoch 18/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.7083 - accuracy: 0.4929\n","Epoch 19/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.6769 - accuracy: 0.4992\n","Epoch 20/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.6527 - accuracy: 0.5051\n","Epoch 21/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.6218 - accuracy: 0.5130\n","Epoch 22/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.5915 - accuracy: 0.5197\n","Epoch 23/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.5675 - accuracy: 0.5254\n","Epoch 24/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.5451 - accuracy: 0.5302\n","Epoch 25/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.5163 - accuracy: 0.5378\n","Epoch 26/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.5118 - accuracy: 0.5387\n","Epoch 27/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.4923 - accuracy: 0.5434\n","Epoch 28/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.4747 - accuracy: 0.5472\n","Epoch 29/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.4692 - accuracy: 0.5483\n","Epoch 30/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.4506 - accuracy: 0.5531\n","Epoch 31/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.4400 - accuracy: 0.5541\n","Epoch 32/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.4202 - accuracy: 0.5599\n","Epoch 33/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.4025 - accuracy: 0.5650\n","Epoch 34/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.4054 - accuracy: 0.5642\n","Epoch 35/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3877 - accuracy: 0.5682\n","Epoch 36/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.3776 - accuracy: 0.5701\n","Epoch 37/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.3668 - accuracy: 0.5718\n","Epoch 38/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3533 - accuracy: 0.5762\n","Epoch 39/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3621 - accuracy: 0.5737\n","Epoch 40/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3500 - accuracy: 0.5769\n","Epoch 41/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3402 - accuracy: 0.5780\n","Epoch 42/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.3241 - accuracy: 0.5846\n","Epoch 43/50\n","344/344 [==============================] - 24s 69ms/step - loss: 1.3336 - accuracy: 0.5795\n","Epoch 44/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3307 - accuracy: 0.5798\n","Epoch 45/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3334 - accuracy: 0.5783\n","Epoch 46/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3275 - accuracy: 0.5811\n","Epoch 47/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3213 - accuracy: 0.5823\n","Epoch 48/50\n","344/344 [==============================] - 24s 68ms/step - loss: 1.3835 - accuracy: 0.5661\n","Epoch 49/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3959 - accuracy: 0.5635\n","Epoch 50/50\n","344/344 [==============================] - 23s 68ms/step - loss: 1.3561 - accuracy: 0.5717\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=50,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/gpt/LEVX/LEVXmodel.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"1yOWuYcWMK3RG2MnDDziPj7B7pBUDedv4","authorship_tag":"ABX9TyNMYjz4GlUk+jwoKL7+QHQE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}