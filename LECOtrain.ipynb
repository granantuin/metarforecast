{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":10009,"status":"ok","timestamp":1718558038715,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"},"user_tz":-120},"id":"AhbFCiyyjPjc","outputId":"785311f5-644a-41db-a929-470cb300d816"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary size (words): len(y[i]): 3333\n","Total X variables: 163928\n","\n","Text train example1\n"]},{"output_type":"display_data","data":{"text/plain":["'16003kt 9999 prec0n CL2 CM0 11 10 q1024 18003KT 9999 NCD 10/10 Q1024'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 1\n"]},{"output_type":"display_data","data":{"text/plain":["[89, 1, 2, 45, 3, 9, 11, 38, 93, 1, 98, 11, 11, 38]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Text train example2\n"]},{"output_type":"display_data","data":{"text/plain":["'25013kt 3000 prec0y CL1 CM1 12 09 q1003 27008G18KT 240V010 9999 FEW022 SCT030TCU 14/09 Q1006 TEMPO SHRA BKN020CB'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Sequences example 2\n"]},{"output_type":"display_data","data":{"text/plain":["[526,\n"," 34,\n"," 20,\n"," 48,\n"," 49,\n"," 6,\n"," 14,\n"," 135,\n"," 2710,\n"," 579,\n"," 1,\n"," 139,\n"," 92,\n"," 8,\n"," 14,\n"," 95,\n"," 17,\n"," 50,\n"," 1116]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","X\n"]},{"output_type":"display_data","data":{"text/plain":["array([[   0,    0,    0,    0,    0,   89,    1,    2,   45,    3,    9,\n","          11,   38],\n","       [   0,    0,    0,    0,   89,    1,    2,   45,    3,    9,   11,\n","          38,   93],\n","       [   0,    0,    0,   89,    1,    2,   45,    3,    9,   11,   38,\n","          93,    1],\n","       [   0,    0,   89,    1,    2,   45,    3,    9,   11,   38,   93,\n","           1,   98],\n","       [   0,   89,    1,    2,   45,    3,    9,   11,   38,   93,    1,\n","          98,   11],\n","       [  89,    1,    2,   45,    3,    9,   11,   38,   93,    1,   98,\n","          11,   11],\n","       [   0,    0,    0,    0,    0,  526,   34,   20,   48,   49,    6,\n","          14,  135],\n","       [   0,    0,    0,    0,  526,   34,   20,   48,   49,    6,   14,\n","         135, 2710],\n","       [   0,    0,    0,  526,   34,   20,   48,   49,    6,   14,  135,\n","        2710,  579],\n","       [   0,    0,  526,   34,   20,   48,   49,    6,   14,  135, 2710,\n","         579,    1],\n","       [   0,  526,   34,   20,   48,   49,    6,   14,  135, 2710,  579,\n","           1,  139],\n","       [ 526,   34,   20,   48,   49,    6,   14,  135, 2710,  579,    1,\n","         139,   92],\n","       [  34,   20,   48,   49,    6,   14,  135, 2710,  579,    1,  139,\n","          92,    8],\n","       [  20,   48,   49,    6,   14,  135, 2710,  579,    1,  139,   92,\n","           8,   14],\n","       [  48,   49,    6,   14,  135, 2710,  579,    1,  139,   92,    8,\n","          14,   95],\n","       [  49,    6,   14,  135, 2710,  579,    1,  139,   92,    8,   14,\n","          95,   17],\n","       [   6,   14,  135, 2710,  579,    1,  139,   92,    8,   14,   95,\n","          17,   50],\n","       [   0,    0,    0,    0,    0,  342,    1,    2,    5,    3,   81,\n","          13,   29],\n","       [   0,    0,    0,    0,  342,    1,    2,    5,    3,   81,   13,\n","          29,  287],\n","       [   0,    0,    0,  342,    1,    2,    5,    3,   81,   13,   29,\n","         287,  111],\n","       [   0,    0,  342,    1,    2,    5,    3,   81,   13,   29,  287,\n","         111,   12],\n","       [   0,  342,    1,    2,    5,    3,   81,   13,   29,  287,  111,\n","          12,   63],\n","       [ 342,    1,    2,    5,    3,   81,   13,   29,  287,  111,   12,\n","          63,   15],\n","       [   1,    2,    5,    3,   81,   13,   29,  287,  111,   12,   63,\n","          15,   32],\n","       [   0,    0,    0,    0,    0,  444,    1,    2,    5,    3,   16,\n","          16,  178]], dtype=int32)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Dictionary first 10 words\n"]},{"output_type":"display_data","data":{"text/plain":["{'9999': 1,\n"," 'prec0n': 2,\n"," 'cm0': 3,\n"," 'nosig': 4,\n"," 'cl0': 5,\n"," '12': 6,\n"," '13': 7,\n"," '14': 8,\n"," '11': 9,\n"," '15': 10}"]},"metadata":{}}],"source":["#@title Get text train and test ,X and Y\n","nrows_train = 20000 # @param {type:\"integer\"}\n","sequence_length = 13 # @param {type:\"integer\"}\n","\n","feed_lenght = 8\n","\n","import pandas as pd\n","import numpy as np\n","import time\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import LSTM, Dense, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.optimizers import Adam\n","import json\n","from keras.preprocessing.text import tokenizer_from_json\n","\n","#load fusion\n","fus = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOfusion.csv\",\n","                  parse_dates=[\"time\"], index_col=\"time\")\n","\n","#Get the train and test train\n","texts_train = fus[\"fusion\"].sample(nrows_train,)\n","texts_test = fus[\"fusion\"].drop(texts_train.index)\n","\n","#save texts test\n","texts_test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOtexts_test.csv\")\n","\n","# Tokenize text\n","tokenizer = Tokenizer()\n","\n","#tokenizer.fit_on_texts(texts_train)\n","tokenizer.fit_on_texts(fus[\"fusion\"])\n","\n","#Save tokenizer\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the JSON configuration to a file\n","with open('/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOtokenizer_config.json', 'w', encoding='utf-8') as f:\n","    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n","\n","sequences = tokenizer.texts_to_sequences(texts_train)\n","\n","# Prepare input and output data\n","X = []\n","y = []\n","for sequence in sequences:\n","    for i in range(1, len(sequence)):\n","        x_seq = sequence[:i]\n","        x_seq_padded = pad_sequences([x_seq], maxlen=sequence_length, padding='pre')\n","        X.append(x_seq_padded[0])\n","        y.append(sequence[i])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","#filter seed/model words\n","df = pd.DataFrame(X)\n","df[\"y\"] = y\n","df_fil =  df[(df.iloc[:, :sequence_length-feed_lenght+1] != 0).any(axis=1)]\n","X = df_fil.iloc[:, :-1].values\n","y = df_fil.iloc[:, -1].values\n","\n","# One hot encode the outputs\n","y = np.eye(len(tokenizer.word_index) + 1)[y]\n","\n","print(\"Dictionary size (words): len(y[i]):\",len(y[1]) )\n","print(\"Total X variables:\",len(X) )\n","\n","print(\"\\nText train example1\")\n","display(texts_train[0])\n","\n","print(\"\\nSequences example 1\")\n","display(sequences[0])\n","\n","print(\"\\nText train example2\")\n","display(texts_train[1])\n","\n","print(\"\\nSequences example 2\")\n","display(sequences[1])\n","\n","print(\"\\nX\")\n","display(X[:25])\n","\n","print(\"\\nDictionary first 10 words\")\n","display({k: tokenizer.word_index[k] for k in list(tokenizer.word_index)[:10]})\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fOX-9Am0V_d","executionInfo":{"status":"ok","timestamp":1718559210645,"user_tz":-120,"elapsed":1122423,"user":{"displayName":"Rosencor Rosencor","userId":"03851350926450566129"}},"outputId":"07a3255e-c638-4149-e6ae-7f0d182ecde4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","321/321 [==============================] - 25s 69ms/step - loss: 4.1228 - accuracy: 0.1946\n","Epoch 2/50\n","321/321 [==============================] - 22s 69ms/step - loss: 2.8905 - accuracy: 0.2890\n","Epoch 3/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.5717 - accuracy: 0.3303\n","Epoch 4/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.4171 - accuracy: 0.3550\n","Epoch 5/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.3192 - accuracy: 0.3707\n","Epoch 6/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.2473 - accuracy: 0.3815\n","Epoch 7/50\n","321/321 [==============================] - 22s 69ms/step - loss: 2.1799 - accuracy: 0.3928\n","Epoch 8/50\n","321/321 [==============================] - 22s 69ms/step - loss: 2.1228 - accuracy: 0.4024\n","Epoch 9/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.0654 - accuracy: 0.4138\n","Epoch 10/50\n","321/321 [==============================] - 22s 68ms/step - loss: 2.0105 - accuracy: 0.4257\n","Epoch 11/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.9612 - accuracy: 0.4353\n","Epoch 12/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.9127 - accuracy: 0.4459\n","Epoch 13/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.8690 - accuracy: 0.4558\n","Epoch 14/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.8311 - accuracy: 0.4635\n","Epoch 15/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.7873 - accuracy: 0.4736\n","Epoch 16/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.7527 - accuracy: 0.4820\n","Epoch 17/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.7207 - accuracy: 0.4905\n","Epoch 18/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.6898 - accuracy: 0.4965\n","Epoch 19/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.6630 - accuracy: 0.5029\n","Epoch 20/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.6350 - accuracy: 0.5101\n","Epoch 21/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.6140 - accuracy: 0.5158\n","Epoch 22/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.5889 - accuracy: 0.5200\n","Epoch 23/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.5694 - accuracy: 0.5279\n","Epoch 24/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.5479 - accuracy: 0.5329\n","Epoch 25/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.5320 - accuracy: 0.5354\n","Epoch 26/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.5095 - accuracy: 0.5403\n","Epoch 27/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.4935 - accuracy: 0.5460\n","Epoch 28/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.4826 - accuracy: 0.5477\n","Epoch 29/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.4652 - accuracy: 0.5521\n","Epoch 30/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.4560 - accuracy: 0.5539\n","Epoch 31/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.4294 - accuracy: 0.5623\n","Epoch 32/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.4201 - accuracy: 0.5654\n","Epoch 33/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.4166 - accuracy: 0.5645\n","Epoch 34/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.4072 - accuracy: 0.5677\n","Epoch 35/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3933 - accuracy: 0.5694\n","Epoch 36/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3874 - accuracy: 0.5725\n","Epoch 37/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3749 - accuracy: 0.5756\n","Epoch 38/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3652 - accuracy: 0.5772\n","Epoch 39/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.3634 - accuracy: 0.5786\n","Epoch 40/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3633 - accuracy: 0.5775\n","Epoch 41/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3592 - accuracy: 0.5785\n","Epoch 42/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.3455 - accuracy: 0.5823\n","Epoch 43/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3410 - accuracy: 0.5825\n","Epoch 44/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3385 - accuracy: 0.5838\n","Epoch 45/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.3301 - accuracy: 0.5858\n","Epoch 46/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3277 - accuracy: 0.5851\n","Epoch 47/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3275 - accuracy: 0.5862\n","Epoch 48/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3353 - accuracy: 0.5833\n","Epoch 49/50\n","321/321 [==============================] - 22s 68ms/step - loss: 1.3160 - accuracy: 0.5893\n","Epoch 50/50\n","321/321 [==============================] - 22s 69ms/step - loss: 1.3107 - accuracy: 0.5894\n"]}],"source":["#@title Train the model\n","\n","from keras.layers import Bidirectional\n","\n","# Build the LSTM model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=20, input_length=sequence_length),\n","    Bidirectional(LSTM(130)),\n","\n","    Dense(len(tokenizer.word_index)+1, activation='softmax')\n","])\n","\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=50,batch_size=512)\n","\n","#save the model\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/gpt/LECO/LECOmodel.keras\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1PKiCntrB2pBLVWZRaL6x-uJpEvPlNmAg","timestamp":1717661221746},{"file_id":"1qsxpGdTrTbO4obEJ4QwGeDJUpuX7gXoW","timestamp":1717492644174},{"file_id":"1LGw-aME2JOnpzAyMOVamYWUAywgSV5mI","timestamp":1715852482288},{"file_id":"1_9maObId68xlnKd6JjYqJUMRMI14ASnx","timestamp":1715845357828},{"file_id":"1BterrhINI5z4G_D4Ntuk7p8a0iuZu7ql","timestamp":1714808806688},{"file_id":"1sqdm_O_jJnvjiOLxkCsuGODjv7CDiB0l","timestamp":1714549345450},{"file_id":"1GD83k4KMSFWH42Th2LjdPwK-hN39h8RT","timestamp":1713425984380}],"mount_file_id":"1HbflTgIgTchocvRL8khB9_lcWWFaZQp5","authorship_tag":"ABX9TyNEoGQb5yPoEEmx0eyLHRSF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}